#! /usr/bin/env python
#
# The Parker Lab (theparkerlab.org)
# University of Michigan, Ann Arbor
#

import itertools
import os
import sys
import functools


if not config['results']:
  print("Project ROOT not set. Check config. Exiting.")
  sys.exit(1)


## Generic data
#
ORGANISMS = {
    'rn4': 'rat',
    'rn5': 'rat',
    'mm9': 'mouse',
    'mm10': 'mouse',
    'hg19': 'human',
    'hg38': 'human'
}

AUTOSOMAL_REFERENCES = {
    'hg19': ['chr{}'.format(i) for i in range(1, 23)],
    'hg38': ['chr{}'.format(i) for i in range(1, 23)],
    'mm9': ['chr{}'.format(i) for i in range(1, 20)],
    'mm10': ['chr{}'.format(i) for i in range(1, 20)],
    'rn4': ['chr{}'.format(i) for i in range(1, 21)],
    'rn5': ['chr{}'.format(i) for i in range(1, 21)]
}

MACS2_GENOME_SIZE = {
    'rn4': 'mm',
    'rn5': 'mm',
    'mm9': 'mm',
    'mm10': 'mm',
    'hg19': 'hs',
    'hg38': 'hs'
}


## Generate paths
#
results = functools.partial(os.path.join, config['results'])

# target directories; relative to root
FASTQC_DIR = results('fastqc')
TRIM_DIR = results('trim')
BWA_DIR = results('bwa')
MERGE_DIR = results('merge_readgroups')
MD_DIR = results('mark_duplicates')
PRUNE_DIR = results('prune')
MACS2_DIR = results('macs2')
ATAQV_DIR = results('ataqv')
MKARV_DIR = results('mkarv')

# paths for downsampled data
DOWNSAMPLE_DIR = results('downsampled')
DOWNSAMPLE_BAM_DIR = results(DOWNSAMPLE_DIR, 'bam')
DOWNSAMPLE_MACS2_DIR = results(DOWNSAMPLE_DIR, 'macs2')
DOWNSAMPLE_ATAQV_DIR = results(DOWNSAMPLE_DIR, 'ataqv')

# logs and other stuff
LOG_DIR = results('logs')
VERSION_DIR = results('versions')


## Helper functions
#
def iterate_all_libraries():
    for library in sorted(config['libraries'].keys()):
        yield library


def iterate_library_readgroups(library):
    for rg in sorted(config['libraries'][library]['readgroups'].keys()):
        yield rg


def readgroup_to_library(readgroup):
    for library in iterate_all_libraries():
        for library_readgroup in iterate_library_readgroups(library):
            if readgroup == library_readgroup:
                return library


def iterate_all_readgroups():
    for library in iterate_all_libraries():
        for readgroup in iterate_library_readgroups(library):
            yield readgroup


def list_readgroup_fastqs(readgroup):
    library = readgroup_to_library(readgroup)
    return config['libraries'][library]['readgroups'][readgroup]


def iterate_all_fastqs():
    for readgroup in iterate_all_readgroups():
        for fastq in list_readgroup_fastqs(readgroup):
            yield fastq


def fastq_basename_to_fastq(fastq_basename):
    for fastq in iterate_all_fastqs():
        if fastq_basename == os.path.basename(fastq):
            return fastq
    sys.stderr.write(
        'ERROR: Could not find FASTQ corresponding to {}; exiting.\n'.format(
            fastq_basename
        )
    )
    sys.exit(1)


def fastq_to_trimmed_fastq(fastq):
    trimmed_fastq_basename = os.path.basename(fastq).replace(
        '.fastq.gz', '.trimmed.fastq.gz'
    )
    return os.path.join(TRIM_DIR, trimmed_fastq_basename)


def get_genome(library):
    return config['libraries'][library]['genome']


def get_organism(genome):
    return ORGANISMS[genome]


def get_autosomes(genome):
    return AUTOSOMAL_REFERENCES[genome]


def get_bwa_index(genome):
    return config['bwa_index'][genome]


def get_tss(genome):
    return config['tss'][genome]


def get_whitelists(genome):
    return config['whitelist'].get(genome)


def get_blacklists(genome):
    return config['blacklist'].get(genome)


# Now the pipeline itself

rule all:
    input:
        # fastqc output
        [
            os.path.join(FASTQC_DIR, '{}_fastqc.zip'.format(
                os.path.basename(fastq).replace('.fastq.gz', ''))
            )
            for fastq in iterate_all_fastqs()
        ],
        # blacklist-filtered master peak files
        [os.path.join(MACS2_DIR, '{}_peaks.master'.format(x)) for x in config['libraries']],
        # ataqv output
        [os.path.join(ATAQV_DIR, '{}.ataqv.json.gz'.format(x)) for x in config['libraries']],
        #
        # software versions
        #
        os.path.join(VERSION_DIR, 'fastqc_version.txt'),
        os.path.join(VERSION_DIR, 'cta_version.txt'),
        os.path.join(VERSION_DIR, 'bwa_version.txt'),
        os.path.join(VERSION_DIR, 'picard_version.txt'),
        os.path.join(VERSION_DIR, 'samtools_version.txt'),
        os.path.join(VERSION_DIR, 'macs2_version.txt'),
        os.path.join(VERSION_DIR, 'bedtools_version.txt'),
        os.path.join(VERSION_DIR, 'ataqv_version.txt')


rule fastqc:
    input:
        lambda wildcards: fastq_basename_to_fastq(
            '{}.fastq.gz'.format(wildcards.fastq_basename)
        )
    output:
        os.path.join(FASTQC_DIR, '{fastq_basename}_fastqc.zip')
    params:
        outdir=FASTQC_DIR
    log:
        os.path.join(LOG_DIR, 'fastqc.{fastq_basename}.log')
    shell:
        'fastqc {input} -o {params.outdir} &> {log}'


rule trim:
    """Use cta to trim adapter sequences"""
    input:
        first = lambda wildcards: fastq_basename_to_fastq(
            '{}.1.fastq.gz'.format(wildcards.fastq_basename)
        ),
        second = lambda wildcards: fastq_basename_to_fastq(
            '{}.2.fastq.gz'.format(wildcards.fastq_basename)
        )
    output:
        first = os.path.join(TRIM_DIR, '{fastq_basename}.1.trimmed.fastq.gz'),
        second = os.path.join(TRIM_DIR, '{fastq_basename}.2.trimmed.fastq.gz')
    shell:
        'cta {input.first} {input.second} {output.first} {output.second}'


rule map:
    """Map reads to reference using BWA MEM algorithm.

    For ATAC-seq data, we use `-I 200,200,5000` flag which correspond to the
    mean, standard deviation, and max limits of the insert size distribution.
    Reads outside this are ignored by BWA. The defaults inferred by BWA are
    not best suited for the typical ATAC-seq insert size distribution if you
    analysis uses larger size fragments.
    """
    input:
        first = lambda wildcards: fastq_to_trimmed_fastq(
            list_readgroup_fastqs(wildcards.readgroup)[0]
        ),
        second = lambda wildcards: fastq_to_trimmed_fastq(
            list_readgroup_fastqs(wildcards.readgroup)[1]
        ),
        index = lambda wildcards: get_bwa_index(get_genome(wildcards.library))
    output:
        os.path.join(BWA_DIR, '{library}______{readgroup}.bam')
    params:
        rg = '\\t'.join(['@RG', 'ID:{}'.format('{readgroup}'), 'LB:{}'.format('{library}')])
    threads: 4
    log:
        bwa = os.path.join(LOG_DIR, 'map.bwa.{library}______{readgroup}.log'),
        samtools = os.path.join(LOG_DIR, 'map.samtools.{library}______{readgroup}.log')
    shell:
        """
        bwa mem -I 200,200,5000 -M -R \'{params.rg}\' -t {threads} {input.index} {input.first} {input.second} 2> {log.bwa} \
            | samtools sort -m 1g -@ {threads} -O bam -o {output} - 2> {log.samtools}"""


rule mark_duplicates:
    input:
        bam = os.path.join(BWA_DIR, '{library}______{readgroup}.bam')
    output:
        bam = os.path.join(MD_DIR, '{library}______{readgroup}.md.bam')
    params:
        metrics = os.path.join(MD_DIR, '{library}______{readgroup}.metrics'),
        tmp_dir = MD_DIR
    shell:
        """
        picard -m 4g MarkDuplicates       \
            I={input.bam}                 \
            O={output.bam}                \
            ASSUME_SORTED=true            \
            METRICS_FILE={params.metrics} \
            VALIDATION_STRINGENCY=LENIENT \
            TMP_DIR={params.tmp_dir}

        ionice -c2 -n7 samtools index {output.bam}
        """


rule merge:
    """Readgroups from a library are merged together into a single BAM file."""
    input:
        lambda wildcards: [
            os.path.join(
                MD_DIR, '{}______{}.md.bam'.format(wildcards.library, readgroup)
            )
            for readgroup in iterate_library_readgroups(wildcards.library)
        ]
    output:
        bam = os.path.join(MERGE_DIR, '{library}.md.bam'),
        bai = os.path.join(MERGE_DIR, '{library}.md.bam.bai'),
    params:
        unsorted_merged_bam = temp(os.path.join(MERGE_DIR, '{library}.unsorted.bam')),
        sort_tmp_prefix = os.path.join(MERGE_DIR, '{library}.sort')
    shell:
        """
        samtools merge {params.unsorted_merged_bam} {input}
        ionice -c2 -n7 samtools sort -m 1G -O bam -T {params.sort_tmp_prefix} -o {output.bam} {params.unsorted_merged_bam}
        samtools index {output.bam}
        """


rule prune:
    """Prune all non-autosomal reads, marked duplicates, and unpaired reads
    giving only properly paired and aligned reads above specified alignment
    quality threshold.
    """
    input:
        bam = os.path.join(MERGE_DIR, '{library}.md.bam'),
        bai = os.path.join(MERGE_DIR, '{library}.md.bam.bai')
    output:
        bam = os.path.join(PRUNE_DIR, '{library}.pruned.bam'),
        bai = os.path.join(PRUNE_DIR, '{library}.pruned.bam.bai')
    params:
        tmp_dir = MD_DIR,
        mapq = 30,
        autosomes = lambda wildcards: get_autosomes(get_genome('{}'.format(wildcards.library)))
    shell:
        """
        samtools view -b -h -f 3 -F 4 -F 8 -F 256 -F 1024 -F 2048 \
            -q {params.mapq} {input.bam} {params.autosomes} > {output.bam}

        samtools index {output.bam}
        """

rule peaks:
    input:
        os.path.join(PRUNE_DIR, '{library}.pruned.bam')
    output:
        os.path.join(MACS2_DIR, '{library}_peaks.broadPeak')
    log:
        os.path.join(MACS2_DIR, '{library}.macs2.out')
    params:
        name = '{library}',
        genome_size = lambda wildcards: MACS2_GENOME_SIZE[get_genome(wildcards.library)],
        outdir = MACS2_DIR
    shell:
        """
        macs2 callpeak \
          --outdir {params.outdir} \
          -t {input} \
          -n {params.name} \
          -f BAM \
          -g {params.genome_size} \
          --nomodel \
          --shift -100 \
          --extsize 200 \
          --seed 2018 \
          -B \
          --broad \
          --keep-dup all \
          --SPMR \
          &> {log}

        """


rule blacklist_filter:
    input:
        os.path.join(MACS2_DIR, '{library}_peaks.broadPeak')
    output:
        os.path.join(MACS2_DIR, '{library}_peaks.master')
    shell:
        """mappability_filter > {output}"""


rule ataqv:
    input:
        md_bam = os.path.join(MD_DIR, '{library}.md.bam'),
        peaks = os.path.join(MACS2_DIR, '{library}_peaks.broadPeak')
    output:
        metrics = os.path.join(ATAQV_DIR, '{library}.ataqv.json.gz'),
    log:
        os.path.join(ATAQV_DIR, '{library}.ataqv.out')
    params:
        name = '{library}',
        description = '{library}', # this should really be {description}
        organism = lambda wildcards: get_organism(get_genome(wildcards.library)),
        tss = lambda wildcards: get_tss(get_genome(wildcards.library)),
        excluded_regions_option = lambda wildcards: ' '.join([
            '--excluded-region-file {}'.format(x) for x in get_blacklists(get_genome(wildcards.library))
        ]) if not get_blacklists(get_genome(wildcards.library)) else ''
    shell:
        """
        ataqv --peak-file {input.peaks}    \
          --name {params.description}      \
          --metrics-file {output.metrics}  \
          {params.excluded_regions_option} \
          --tss-file {params.tss}          \
          --ignore-read-groups             \
          {params.organism}                \
          {input.md_bam}                   \
          > {log}
        """


##
# 2. (optional) Perform downsampling; call `rule downsample` directly
##
rule downsample:
    input:
        [os.path.join(DOWNSAMPLE_BAM_DIR, '{}.downsampled.bam'.format(x)) for x in config['libraries']],
        [os.path.join(DOWNSAMPLE_MACS2_DIR, '{}_peaks.broadPeak.noblacklist'.format(x)) for x in config['libraries']],
        [os.path.join(DOWNSAMPLE_ATAQV_DIR, '{}.ataqv.json.gz'.format(x)) for x in config['libraries']]


rule __dwnsmpl_bam:
  input:
        bam = os.path.join(PRUNE_DIR, '{library}.pruned.bam'),
        bai = os.path.join(PRUNE_DIR, '{library}.pruned.bam.bai')
  output:
        bam = os.path.join(DOWNSAMPLE_BAM_DIR, '{library}.downsampled.bam'),
        bai = os.path.join(DOWNSAMPLE_BAM_DIR, '{library}.downsampled.bam.bai')
  threads: 1
  params:
        seed = 2018,
        depth = config.get('subsample_depth')
  shell:
      # if not supplied; no need to downsampled, just error and exit
      if params.depth is None:
          sys.stderr.write("ERROR: Subsampling depth not supplied; Exiting!\n")
          sys.exit(1)
      else:
          # Compute desired fraction of reads to sub-sample using samtools
          # flagstat.
          #
          # __TOTAL_READS computes the total number of # "single-reads" in the
          # given input BAM file, and then we compute the fraction to subsample
          # in __FRACTION (requires `bc` tools, POSIX so almost always
          # available). The __FRACTION value already contains a '.' (period) so
          # we omit that in samtools call. `scale=3` in `bc -l` limits the number
          # of decimal places to 3.
          #
          # Further, simply symlink files if desired depth is more then available
          # number of reads in the file.
          #
          # Note, (( . )) is not a typo. Using BASH's arithmetic context.
        shell(
        """
            __TOTAL_READS=$(samtools flagstat {input.bam} | head -n1 | cut -d'+' -f1) \
            && if (( $_TOTAL_READS < {params.depth} )); then
                ln -s {input.bam} {output.bam}
                ln -s {input.bai} {output.bai}
            else
                __FRACTION=$(bc -l <<< "scale=3; {params.depth}/$__TOTAL_READS") \
                && samtools view -@ {threads} -b -h -s {params.seed}$__FRACTION {input.bam} -o {output.bam}
                samtools index {output.bam}
            fi
        """
        )
       

rule __dwnsmpl_call_peaks:
    input:
        os.path.join(DOWNSAMPLE_BAM_DIR, '{library}.downsampled.bam')
    output:
        os.path.join(DOWNSAMPLE_MACS2_DIR, '{library}_peaks.broadPeak')
    log:
        os.path.join(DOWNSAMPLE_MACS2_DIR, '{library}.macs2.out'),
    params:
        name = '{library}',
        genome_size = lambda wildcards: MACS2_GENOME_SIZE[get_genome(wildcards.library)],
        outdir = DOWNSAMPLE_MACS2_DIR
    shell:
        """
        macs2 callpeak \
          --outdir {params.outdir} \
          -t {input} \
          -n {params.name} \
          -f BAM \
          -g {params.genome_size} \
          --nomodel \
          --shift -100 \
          --extsize 200 \
          --seed 2018 \
          -B \
          --broad \
          --keep-dup all \
          --SPMR \
          &> {log}

        """


rule __dwnsmpl_noblacklist:
    input:
        os.path.join(DOWNSAMPLE_MACS2_DIR, '{library}_peaks.broadPeak')
    output:
        os.path.join(DOWNSAMPLE_MACS2_DIR, '{library}_peaks.broadPeak.noblacklist')
    shell:
        """mappability_filter {input} > {output}"""


rule __dwnsmpl_ataqv:
    input:
        bam = os.path.join(DOWNSAMPLE_BAM_DIR, '{library}.downsampled.bam'),
        peaks = os.path.join(DOWNSAMPLE_MACS2_DIR, '{library}_peaks.broadPeak')
    output:
        metrics = os.path.join(DOWNSAMPLE_ATAQV_DIR, '{library}.ataqv.json.gz'),
        stdout_destination = os.path.join(DOWNSAMPLE_ATAQV_DIR, '{library}.ataqv.out')
    params:
        name = '{library}',
        description = '{library}', # this should really be {description}
        organism = lambda wildcards: get_organism(get_genome(wildcards.library)),
        tss_file = lambda wildcards: get_tss(get_genome(wildcards.library)),
        excluded_regions_option = lambda wildcards: ' '.join(['--excluded-region-file {}'.format(x) for x in get_blacklists(get_genome(wildcards.library))]) if get_blacklists(get_genome(wildcards.library)) is not None else ''
    shell:
        """
        ataqv --peak-file {input.peaks}    \
          --name {params.description}      \
          --metrics-file {output.metrics}  \
          {params.excluded_regions_option} \
          --tss-file {params.tss}          \
          --ignore-read-groups             \
          {params.organism}                \
          {input.bam}                      \
          > {log}
        """


##
## debug info
##

rule versions:
    output:
        fastqc_version = os.path.join(VERSION_DIR, 'fastqc_version.txt'),
        cta_version = os.path.join(VERSION_DIR, 'cta_version.txt'),
        bwa_version = os.path.join(VERSION_DIR, 'bwa_version.txt'),
        picard_version = os.path.join(VERSION_DIR, 'picard_version.txt'),
        samtools_version = os.path.join(VERSION_DIR, 'samtools_version.txt'),
        macs2_version = os.path.join(VERSION_DIR, 'macs2_version.txt'),
        bedtools_version = os.path.join(VERSION_DIR, 'bedtools_version.txt'),
        ataqv_version = os.path.join(VERSION_DIR, 'ataqv_version.txt')
    run:
        shell('fastqc --version &> {output.fastqc_version} || echo ""')
        shell('cta --version &> {output.cta_version} || echo ""')
        shell('bwa &> {output.bwa_version} || echo ""')
        shell('picard MarkDuplicates --version &> {output.picard_version} || echo ""')
        shell('samtools --version &> {output.samtools_version} || echo ""')
        shell('macs2 --version &> {output.macs2_version} || echo ""')
        shell('bedtools --version &> {output.bedtools_version} || echo ""')
        shell('ataqv --version &> {output.ataqv_version} || echo ""')

##
## notification
##

onerror:
  print("Error: Snakemake aborted!")
  shell("mail -s 'Snakemake Job Error: See log inside!' {config[email]} < {log}")


onsuccess:
  print("Success: Snakemake completed!")
  shell("mail -s 'Snakemake Job Completed: Have a Beer!' {config[email]} < {log}")

# vim: syntax=snakemake
